{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call the model and test\n",
    "from skimage import io,transform\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory of data\n",
    "path = 'D:/AI/HCIA/Abroad/Lab/Data/flower_photos/'\n",
    "# the saved modle directory\n",
    "model_path = './model/'\n",
    "# the name of modle\n",
    "model_name = 'CNN_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test images\n",
    "path1 = \"daisy/5547758_eea9edfd54_n.jpg\"\n",
    "path2 = \"roses/394990940_7af082cf8d_n.jpg\"\n",
    "path3 = \"dandelion/7355522_b66e5d3078_m.jpg\"\n",
    "path4 = \"tulips/10791227_7168491604.jpg\"\n",
    "path5 = \"sunflowers/6953297_8576bf4ea3.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = path+path1\n",
    "path2 = path+path2\n",
    "path3 = path+path3\n",
    "path4 = path+path4\n",
    "path5 = path+path5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_dict = {0:'dasiy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'}\n",
    "w=100\n",
    "h=100\n",
    "c=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test image and resize the images\n",
    "def read_one_image(path):\n",
    "    img = io.imread(path)\n",
    "    img = transform.resize(img,(w,h),mode='constant')\n",
    "    return np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "data = []\n",
    "data1 = read_one_image(path1)\n",
    "data2 = read_one_image(path2)\n",
    "data3 = read_one_image(path3)\n",
    "data4 = read_one_image(path4)\n",
    "data5 = read_one_image(path5)\n",
    "data.append(data1)\n",
    "data.append(data2)\n",
    "data.append(data3)\n",
    "data.append(data4)\n",
    "data.append(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9759 0.016  0.0065 0.0007 0.001 ]\n",
      " [0.     0.     0.9794 0.0002 0.0203]\n",
      " [0.3594 0.1807 0.1478 0.231  0.0811]\n",
      " [0.0001 0.0001 0.0509 0.0677 0.8812]\n",
      " [0.0003 0.0008 0.0006 0.9852 0.0131]]\n",
      "[0 2 0 4 3]\n",
      "The prediction of fisrt flower is:dasiy\n",
      "The prediction of second flower is:roses\n",
      "The prediction of third flower is:dasiy\n",
      "The prediction of fourth flower is:tulips\n",
      "The prediction of fifth flower is:sunflowers\n"
     ]
    }
   ],
   "source": [
    "# start the session\n",
    "with tf.Session() as sess:\n",
    "    #latrest model path\n",
    "    model_file=tf.train.latest_checkpoint(model_path)\n",
    "    # import computive graph\n",
    "    saver = tf.train.import_meta_graph(model_file+'.meta')\n",
    "    # restore weight ingformation\n",
    "    saver.restore(sess, model_file) \n",
    "    graph = tf.get_default_graph()\n",
    "    # calculate the input nodes in graph\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    # feed information\n",
    "    feed_dict = {x:data}\n",
    "    # calculate the output nodes in graph\n",
    "    logits = graph.get_tensor_by_name(\"logits_eval:0\")\n",
    "    # run the session\n",
    "    classification_result = sess.run(logits,feed_dict)\n",
    "    #diplay 4 decimals\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    #print the prediction \n",
    "    print(classification_result)\n",
    "    #print the maximum in the matrix\n",
    "    print(tf.argmax(classification_result,1).eval())\n",
    "    #Match category of flowers\n",
    "    output = []\n",
    "    output = tf.argmax(classification_result,1).eval()\n",
    "    name=[\"fisrt\",\"second\",\"third\",\"fourth\",\"fifth\"]\n",
    "    for i in range(len(output)):\n",
    "        print(\"The prediction of %s flower is:\" %(name[i])+flower_dict[output[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF1]",
   "language": "python",
   "name": "conda-env-TF1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
